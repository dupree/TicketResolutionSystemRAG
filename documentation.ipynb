{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d15905-815b-4994-ae1c-0ba7b91eb779",
   "metadata": {},
   "source": [
    "# Documentation for Aleph Alpha AI Solutions Engineer Case Study\n",
    "\n",
    "## **Introduction**\n",
    "This documentation outlines the approach, assumptions, and considerations taken to build a **Minimum Viable Product (MVP)** for the case study provided by Aleph Alpha. The goal was to create a system that assists IT helpdesk agents by leveraging previously resolved tickets to provide guidance for solving new tickets. The solution is implemented as a **Streamlit app** that uses **Hugging Face models** for ticket matching and resolution generation.\n",
    "\n",
    "---\n",
    "\n",
    "## **Problem Understanding**\n",
    "The client runs IT helpdesks for various companies and faces the challenge of redundant tickets. Agents often lack awareness of previously resolved tickets, leading to inefficiencies. The goal is to build a feature that:\n",
    "1. **Matches new tickets** to similar past tickets.\n",
    "2. **Provides guidance** to agents based on past resolutions.\n",
    "\n",
    "The solution should **assist agents** rather than fully automate the process, ensuring that human expertise remains central.\n",
    "\n",
    "---\n",
    "\n",
    "## **Exploratory Data Analysis (EDA) Findings**\n",
    "\n",
    "### **1. Dataset Overview**  \n",
    "The dataset consists of **resolved and new tickets** stored across multiple file formats (**CSV, XLSX, JSON**).  \n",
    "\n",
    "#### **Resolved Tickets**  \n",
    "- **30 resolved tickets** from three sources:  \n",
    "  - `ticket_dump_1.csv`, `ticket_dump_2.xlsx`, `ticket_dump_3.json`.  \n",
    "- Each ticket contains **8 key fields**:  \n",
    "  - `Ticket ID`, `Issue`, `Category`, `Resolution`, `Date`, `Agent Name`, `Resolved`, `Description`.  \n",
    "\n",
    "#### **New Tickets**  \n",
    "- **10 new tickets** stored in `new_tickets.csv`.  \n",
    "- Contains **5 fields**:  \n",
    "  - `Ticket ID`, `Issue`, `Description`, `Category`, `Date`.  \n",
    "\n",
    "### **2. Data Structure & Quality**  \n",
    "- Fields are mostly **categorical** (`object`), with `Resolved` as a **boolean**.  \n",
    "- **No missing values** were found.  \n",
    "- **Each ticket has a unique `Ticket ID`**, ensuring data integrity.  \n",
    "\n",
    "### **3. Key Insights**  \n",
    "- **Issue & Category**: Provide structured grouping for classification.  \n",
    "- **Resolution Field**: Contains valuable information for **retrieval-based solutions**.  \n",
    "- **Description Field**:  \n",
    "  - Captures additional context, aiding **semantic search**.  \n",
    "  - **Text length distribution**:  \n",
    "    - Min: **51 characters**, Max: **141 characters**, Avg: **89.5 characters**.  \n",
    "- **Resolved Field**: Indicates **closed vs. open tickets**, useful for filtering relevant solutions.  \n",
    "\n",
    "### **4. Potential Use Cases**  \n",
    "- **Retrieval-Augmented Generation (RAG)**: `Issue`, `Category`, and `Resolution` fields can help improve response accuracy.  \n",
    "- **Classification Models**: `Category` can be used to predict issue types.  \n",
    "- **Search Optimization**: `Description` and `Resolution` aid in **vector search retrieval**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Approach**\n",
    "The solution implements a **Retrieval-Augmented Generation (RAG)** architecture with a user interface layer. It is divided into three main components\n",
    "\n",
    "### 1. **Retrieval Component (Ticket Matching System)**\n",
    "\n",
    "#### **Objective:**  \n",
    "Find and retrieve similar tickets from a knowledge base.  \n",
    "\n",
    "### **Implementation:**  \n",
    "- Uses **Sentence Transformers** (`all-MiniLM-L6-v2`) to generate embeddings for ticket descriptions.  \n",
    "- Leverages **HNSWLib** for efficient vector similarity search to find **top-k similar tickets**.  \n",
    "- Embeddings are generated using a combination of the **Issue, Category, and Description** fields.  \n",
    "- Retrieves both **resolved** and **unresolved** similar tickets with similarity scores.  \n",
    "\n",
    "### 2. **Augmentation & Generation Component (Ticket Resolution System)** \n",
    "\n",
    "#### **Objective:**  \n",
    "Enhance **LLM prompts** with retrieved context and generate a coherent response based on similar tickets.  \n",
    "\n",
    "### **Implementation:**  \n",
    "- Utilizes **Hugging Face Inference API** with `mistralai/Mixtral-8x7B-Instruct-v0.1`.  \n",
    "- Augments LLM prompts with retrieved **similar tickets and their resolutions**.  \n",
    "- Generates responses based on context type:  \n",
    "  - **With Resolved Tickets:** Leverages successful historical solutions.  \n",
    "  - **With Unresolved Tickets:** Suggest potential next steps based on historical attempts.  \n",
    "  - **No Matching Tickets:** In case of no matching past tickets found, informs the agent accordingly.\n",
    "\n",
    "### 3. **User Interface Layer (Streamlit UI)**\n",
    "\n",
    "#### **Objective**: Provide a user-friendly interface for agents to interact with the **RAG system**.\n",
    "\n",
    "#### **Implementation**:\n",
    "  - Agents input the **Issue**, **Category**, and **Description** of a new ticket.\n",
    "  - The app displays:\n",
    "    - **Similar Tickets**: Top `k` resolved or unresolved tickets.\n",
    "    - **AI-Generated Response**: A suggested resolution or guidance for the agent.\n",
    "\n",
    "### **Architecture Diagram**\n",
    "Below is the architecture diagram for the system:\n",
    "\n",
    "![Architecture Diagram](ticket_resolution_system_architecture.png)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Assumptions**\n",
    "1. **Data Format**: The ticket data is assumed to be in a structured format with fields like `Issue`, `Category`, `Description`, `Resolved`, and `Resolution`.\n",
    "2. **Historical Ticket Data & Pre-built Index**:  \n",
    "   The system relies on an aggregated data file (`combined_data.csv`) that stores past ticket details in the specified `data-format`. Additionally, to ensure a faster Streamlit app, it assumes the presence of a cached pre-built index (`ticket_index.bin`).\n",
    "\n",
    "3. **API Availability**: The solution relies on the Hugging Face Inference API, assuming it is available and responsive.\n",
    "4. **User Input**: Agents will provide **clear and relevant input** for the system to generate meaningful responses.\n",
    "\n",
    "---\n",
    "\n",
    "## **Results**\n",
    "The MVP successfully:\n",
    "1. **Matches Tickets**: Finds similar tickets based on user input.\n",
    "2. **Generates Responses**: Provides coherent guidance for agents based on resolved or unresolved tickets.\n",
    "3. **Provides a User Interface**: Offers a simple and intuitive interface for agents to interact with the system.\n",
    "\n",
    "### **Example Output**\n",
    "For a new ticket with the issue **\"Printer not connecting to WiFi\"**, the system might:\n",
    "- Display similar resolved tickets with solutions like **\"Restart the printer and reconnect to the WiFi network.\"**\n",
    "- Generate an AI response: **\"Based on past tickets, try restarting the printer and reconnecting to the WiFi network. If the issue persists, check the printer's network settings. Best, your Smart assistant.\"**\n",
    "\n",
    "---\n",
    "## **How to Run the Code**\n",
    "1. Install the required dependencies:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "\n",
    "   export HUGGINGFACE_API_KEY=\"your_api_key_here\"\n",
    "2. Launch streamlit web application\n",
    "   ```bash\n",
    "   streamlit run streamlit_app.py\n",
    "3. Open the app in your browser and input the ticket details to see the results.\n",
    "\n",
    "---\n",
    "\n",
    "## **Shortcomings**  \n",
    "\n",
    "While the current system implements a **Retrieval-Augmented Generation (RAG)** approach effectively, it has several limitations that impact scalability, performance, and maintainability.  \n",
    "\n",
    "### 1. Scalability & Performance  \n",
    "- **In-Memory Processing:** The system may struggle with large datasets due to memory constraints.  \n",
    "- **Inefficient Vector Search:** Every request triggers a fresh vector search, even for repeated queries.  \n",
    "- **Synchronous API Calls:** UI performance may degrade due to blocking calls to external APIs.  \n",
    "- **Lack of Caching:** No caching mechanism for frequently requested tickets, leading to redundant computations.  \n",
    "\n",
    "### 2. Real-Time Updates & Persistence  \n",
    "- **Index Rebuilding Overhead:** The vector index must be rebuilt every time new tickets are added, making real-time updates inefficient.  \n",
    "- **No Interaction Storage:** User interactions and resolutions are not stored for future learning or analysis.  \n",
    "\n",
    "### 3. Error Handling & Resilience  \n",
    "- **No Robust Error Handling:** The system lacks mechanisms to handle model failures or API downtime.  \n",
    "- **No Retry Mechanisms:** Failed API calls do not have automated retries.  \n",
    "- **Missing Fallback Strategy:** If the LLM service is unavailable, the system has no alternative response mechanism.  \n",
    "- **Lack of Input Validation:** User inputs are not thoroughly validated or sanitized.  \n",
    "\n",
    "### 4. Architecture Limitations  \n",
    "- **Monolithic Streamlit Instance:** Everything runs in a single instance, limiting scalability.  \n",
    "- **No Separation of Services:** The vector search and LLM components are tightly coupled.  \n",
    "- **Local File Dependencies:** The system relies on local files (`index_path`, `resolved_tickets_path`), restricting flexibility.  \n",
    "\n",
    "### 5. Dependency on External APIs  \n",
    "- **Latency & Availability Risks:** The system depends on the Hugging Face API, which may introduce delays and potential service disruptions.  \n",
    "- **API Cost & Usage Monitoring:** There is no tracking of API usage or costs, which could lead to unexpected expenses.  \n",
    "\n",
    "\n",
    "### 6. Monitoring & Maintenance  \n",
    "- **No Logging System:** Errors and performance metrics are not tracked.  \n",
    "- **No Model Telemetry:** The system lacks insights into how well the model is performing.  \n",
    "- **No Feedback Loop:** User interactions are not leveraged to improve future responses.  \n",
    "\n",
    "### 7. Model Optimization  \n",
    "- **Heavy Model Usage:** The current LLM (`mistralai/Mixtral-8x7B-Instruct-v0.1`) is resource-intensive.  \n",
    "- **Lack of Fine-Tuning:** Using a smaller, fine-tuned model could reduce inference time and costs.  \n",
    "\n",
    "---\n",
    "## **Future Improvements**  \n",
    "\n",
    "If more time and resources were available, the following improvements could be made to enhance scalability, performance, and usability. \n",
    "\n",
    "### 1. **Improving the Underlying Algorithm**  \n",
    "\n",
    "- **Weighted Matching for Ticket Components:** Assign different importance levels to fields like **Category** to improve retrieval accuracy.  \n",
    "- **Optimized Similarity Threshold:** Instead of using a fixed **K=3**, determine the best threshold using domain knowledge and data.  \n",
    "- **Better Prompt Engineering:** Ensure the model limits solutions to the knowledge base rather than generating generic responses when no resolved ticket is found.  \n",
    "- **Model Optimization:**  \n",
    "  - Use **smaller, fine-tuned models** for faster inference and lower resource usage.  \n",
    "  - Experiment with **low-latency models** optimized for real-time retrieval and generation.  \n",
    "\n",
    "### 2. **Enhancing System Design**  \n",
    "\n",
    "#### **Scalability & Performance**  \n",
    "- **Vector Database Integration:** Replace the in-memory index with a **vector database** (e.g., **FAISS, Pinecone**) for efficient similarity search and real-time updates.  \n",
    "- **Asynchronous Processing:** Implement **async processing** to handle multiple requests concurrently without blocking UI interactions.  \n",
    "- **Caching for Faster Responses:** Implement caching for **frequent queries** to reduce redundant computations and improve response time.  \n",
    "\n",
    "#### **Real-Time Updates & Persistence**  \n",
    "- **Dynamic Knowledge Base Updates:** Enable users to **add new tickets** dynamically without requiring a full index rebuild.  \n",
    "- **Store User Interactions:** Log past queries and generated responses to **improve model performance** over time.  \n",
    "\n",
    "#### **Architectural Improvements**  \n",
    "- **Microservices Architecture:** Break the monolithic system into separate services for:  \n",
    "  - Vector search  \n",
    "  - Language model inference  \n",
    "  - UI layer  \n",
    "- **Adjustable Search Parameters:** Provide power users with controls to **tweak K-values and similarity thresholds** for fine-tuning retrieval.  \n",
    "- **Improved Testing & Validation:** Develop **dedicated testing modules** to ensure robustness in data ingestion, model inference, and API interactions.  \n",
    "\n",
    "#### **Error Handling & Security**  \n",
    "- **Robust Error Handling:** Implement proper error handling for:  \n",
    "  - API failures  \n",
    "  - Invalid inputs  \n",
    "  - Index loading issues  \n",
    "- **Security Enhancements:**  \n",
    "  - Implement authentication & authorization mechanisms to restrict access.  \n",
    "\n",
    "These improvements will significantly enhance the systemâ€™s accuracy, flexibility, and overall performance. ðŸš€  \n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "The MVP provides a functional solution for assisting IT helpdesk agents by leveraging past ticket resolutions. While the system has some limitations, it demonstrates a clear approach to solving the problem and provides a foundation for future improvements. With additional time and resources, the system could be enhanced to handle larger datasets, improve scalability, and provide a more robust user experience.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
